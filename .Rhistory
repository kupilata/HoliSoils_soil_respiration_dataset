select(-Mod, -pos)
# separate db into uruguayin and others based on condition
condition_uruguay <- db$siteid == "RincondelBatovi"
db_uruguay <- db %>% filter(condition_uruguay)
# CHecking
tubet <- as.character(unique(rdb$tube.number))
sum(db_uruguay$point %in% tubet) / dim(db_uruguay)[1] # How many of the observations are in tube points
# temp
summary(db_uruguay$t10); summary(db_uruguay$t05); summary(db_uruguay$t30) # check how many temp are included
# we also need to add temperature
# Check for duplicates in each dataset
db_uruguay %>%
count(point, date, trenched, j_flux) %>% # how many duplicates with same point/date/trenched/flux combo
filter(n > 1)
moisture_uruguay %>%
mutate(soil_moisture = round(soil_moisture, 4)) %>%
count(tube.number, Date, trenched) %>%  # how many duplicates with same point/date/trenched combo
filter(n > 1)
# LETS CLEAR DUPLICATES AND AGGREGATE
dup_keys <- moisture_uruguay %>%
count(tube.number, Date, trenched) %>%
filter(n > 1) %>%
select(tube.number, Date, trenched)
# Separate rows with true identical and ones with different values
# rows that share same moist/temp
identical_rows <- moisture_uruguay %>%
semi_join(dup_keys, by = c("tube.number", "Date", "trenched")) %>%
group_by(tube.number, Date, trenched, soil_moisture, T1_belowgr) %>%
filter(n() > 1) %>%
ungroup
# Rows where duplicates have different moisture/temp (conflicts)
conflicting_rows <- moisture_uruguay %>%
semi_join(dup_keys, by = c("tube.number", "Date", "trenched")) %>%
group_by(tube.number, Date, trenched) %>%
filter(n_distinct(soil_moisture) > 1 | n_distinct(T1_belowgr) > 1) %>%
ungroup()
# print to inspect
identical_rows %>%
arrange(tube.number, Date, trenched) %>%
print(n = Inf)
conflicting_rows %>%
arrange(tube.number, Date, trenched) %>%
print(n = Inf)
# Collapse duplicate rows
moisture_uruguay <- moisture_uruguay %>%
group_by(tube.number, Date, trenched) %>%
summarise(
soil_moisture = if_else(
n_distinct(soil_moisture) == 1, # identical moistures?
first(soil_moisture), # yes -> take any (first)
mean(soil_moisture, na.rm = TRUE) # no -> take mean
),
T1_belowgr = if_else(
n_distinct(T1_belowgr) == 1,
first(T1_belowgr),
mean(T1_belowgr, na.rm = TRUE)
),
.groups = "drop"
)
# Check duplicate rows again to confirm succesful collapsing
moisture_uruguay %>%
mutate(soil_moisture = round(soil_moisture, 4)) %>%
count(tube.number, Date, trenched) %>%  # how many duplicates with same point/date/trenched combo
filter(n > 1)
# JOINING
db_uruguay <- db_uruguay %>%
left_join(
moisture_uruguay,
by = c("point" = "tube.number", "date" = "Date", "trenched")
) %>%
mutate(
tsmoisture = if_else(is.na(tsmoisture) , soil_moisture * 100, tsmoisture),
t05 = if_else(is.na(t05), T1_belowgr, t05) # assumed that TOMST measures temperature at 5cm depth
) %>%
select(-soil_moisture, -T1_belowgr)
hist(db_uruguay$tsmoisture)
# ===========
# SAINT MITRE
# ===========
# separate db into saintmitre and others based on condition
condition_sm <- db$siteid == "Saint Mitre"
db_sm <- db %>% filter(condition_sm)
db_sm$point <- as.integer(db_sm$point)
# check
table_counts <- table(db_sm$point, db_sm$treatment)
rowSums(table_counts > 0) > 1
print(table_counts)
table_subsite <- table(db_sm$point, db_sm$subsiteid)
print(table_subsite)
colnames(table_subsite) <- c("ht_uv", "ht_nuv", "ht_t", "mt_uv", "mt_nuv", "mt_t", "nt_nuv", "nt_t")
print(table_subsite)
# ==================================
library(dplyr)
library(lubridate)
library(tidyr)
library(stringr)
library(ggplot2)
library(readr)
# Moisture joining
setwd("/scratch/project_2010938/Taavi_new/")
# Read in database file
db <- read.csv("holisoils_recoded.csv", header = TRUE, check.names = FALSE) # database file
db %>%
group_by(siteid) %>%
summarise(
min = min(tsmoisture, na.rm = TRUE),
max = max(tsmoisture, na.rm = TRUE),
mean = mean(tsmoisture, na.rm = TRUE),
n = n()
) %>%
arrange(desc(max))
# update date and add row_id for preserving order
db <- db %>%
mutate(
date = as.Date(date),
row_id = row_number() # preserve row order
)
# ========
# KARSTULA
# ========
# Lets choose the columns of interests and calculate mean for each scout per day.
# define measuring points
measuring_points <- c("1C", "4N", "7C", "8N")
# define the base path
base_file <- "moisturedata/karstula/2025-02-01_soil-scout_export_"
# Choose columns that we are interested in
column_of_interest <- c("Timestamp..UTC.", "Scout.name", "Moisture")
# Create list for storage of data
karstula <- list()
for (i in measuring_points) {
# name for reading the data
name <- paste0("karstula_", i)
# read the data and filter out unwanted columns
df <- read.csv(paste0(base_file, name, ".csv"), header = TRUE)
df <- df[, column_of_interest]
# convert time
df$Timestamp <- ymd_hms(df$Timestamp..UTC., tz = "UTC", quiet = TRUE)
df$date <- as.Date(df$Timestamp)
# calculate mean for each day / scout.name combination
df <- df %>%
group_by(date, Scout.name) %>%
summarise(mean_value = mean(Moisture * 100, na.rm = TRUE), .groups = "drop")
# save data to list
karstula[[i]] <- df
}
karstula <- bind_rows(karstula)
# extract components from karstula$Scout.name
moisture_list_karstula <- karstula %>%
mutate(
point_prefix = str_extract(Scout.name, "^[^-]+-[0-9]+"),
trenched_flag = case_when(
str_ends(Scout.name, "T") ~ "True",
str_ends(Scout.name, "C") ~ "False",
TRUE ~ NA_character_
)
) %>% # remove the trailing "-" from point_prefix to match db$point
mutate(point_prefix = str_remove(point_prefix, "-")) %>%
select(point_prefix, trenched_flag, date, mean_value)
# separate db into Karstula and others based on condition
condition_karstula <- db$siteid %in% c("Karstula75", "Karstula76")
db_karstula <- db %>% filter(condition_karstula)
# join and update only the filtered part
# extract prefix from db$point for joining
db_karstula <- db_karstula %>%
mutate(
point_prefix = str_extract(point, "^[^_]+")
) %>%
left_join(
moisture_list_karstula,
by = c("point_prefix", "trenched" = "trenched_flag", "date")
) %>%
mutate(
tsmoisture = if_else(is.na(tsmoisture) , mean_value, tsmoisture)
) %>%
select(-mean_value, -point_prefix)
# ========
# Ränskälä
# ========
load("moisturedata/ränskälä/TMS4_data_RK_2020_2025.Rdata")
# add mean moisture per treatment
#moisture_ränskälä <- d.tw3 %>% # this data has the daily averages for each treatment
#  select(canopy, date, swc.mean) %>%
#  mutate(
#    canopy = if_else(
#      canopy == "CCF",
#      "Thinning",
#      canopy
#    )
#  )
# separate db into Ränskälä and others based on condition
condition_ränskälä <- db$siteid == "Ränskälänkorpi"
db_ränskälä <- db %>% filter(condition_ränskälä)
# check how many ränskälä plots match to db points
ränskälä_points <- unique(db_ränskälä$point)
d_points <- grep("^[0-9]+/.+", ränskälä_points, value = TRUE)
print(d_points)
# clean moisture data to have mean moisture per plot/date combo
moisture_ränskälä <- TMS4_data_RSK %>%
select(Plot, Canopy_treatment, date, swc) %>%
mutate(
Canopy_treatment = case_when(
Canopy_treatment == "CCF" ~ "Thinning",
Canopy_treatment == "Non_harvested control" ~ "Control",
TRUE ~ Canopy_treatment
)
) %>%
group_by(date, Plot, Canopy_treatment) %>%
summarise(daily_mean_swc = mean(swc, na.rm = TRUE),
.groups = "drop")
# Create a joining key for db_ränskälä
db_ränskälä <- db_ränskälä %>%
mutate(key = trimws(point),
key = case_when(
grepl("^[0-9]+", key) ~ sub("^([0-9]+).*", "\\1", key),  # numeric prefix as string
TRUE ~ key)
)
# check how large proportion of moisture_ränskälä directly match with db_ränskälä
matches <- db_ränskälä$key %in% moisture_ränskälä$Plot
print(paste0("The fraction of observations that match moisture plots directly is: ",
round(mean(matches), 4),
". And the total number of matches is: ",
sum(matches)))
# join and update only the filtered part
# extract prefix from db$point for joining
db_ränskälä <- db_ränskälä %>%
left_join(
moisture_ränskälä,
by = c("key" = "Plot", "date", "treatment" = "Canopy_treatment")
) %>%
mutate(
tsmoisture = coalesce(tsmoisture, daily_mean_swc)) %>%
select(-daily_mean_swc, -key)
print(mean(!is.na(db_ränskälä$tsmoisture)))
# =======
# URUGUAY
# =======
rdb <- read.csv("moisturedata/uruguay/resp_data_rdb.csv", sep = ";", header = TRUE)
hist(rdb$soil_moisture)
# add moisture
moisture_uruguay <- rdb %>%
select(tube.number, Date, pos, Mod, soil_moisture, T1_belowgr) %>%
mutate(Date = as.Date(Date, format = "%m/%d/%Y"),
tube.number = as.character(tube.number),
trenched = case_when(
pos == "Out" ~ "False",
pos == "In" ~ "True",
TRUE ~ NA_character_
),
details = case_when(
Mod == "CN" ~ "Natural Pasture",
Mod == "Fbt" ~ "Forest Between Row",
Mod == "Fin" ~ "Forest In Row",
TRUE ~ NA_character_
)
) %>%
select(-Mod, -pos)
# separate db into uruguayin and others based on condition
condition_uruguay <- db$siteid == "RincondelBatovi"
db_uruguay <- db %>% filter(condition_uruguay)
# CHecking
tubet <- as.character(unique(rdb$tube.number))
sum(db_uruguay$point %in% tubet) / dim(db_uruguay)[1] # How many of the observations are in tube points
# temp
summary(db_uruguay$t10); summary(db_uruguay$t05); summary(db_uruguay$t30) # check how many temp are included
# we also need to add temperature
# Check for duplicates in each dataset
db_uruguay %>%
count(point, date, trenched, j_flux) %>% # how many duplicates with same point/date/trenched/flux combo
filter(n > 1)
moisture_uruguay %>%
mutate(soil_moisture = round(soil_moisture, 4)) %>%
count(tube.number, Date, trenched) %>%  # how many duplicates with same point/date/trenched combo
filter(n > 1)
# LETS CLEAR DUPLICATES AND AGGREGATE
dup_keys <- moisture_uruguay %>%
count(tube.number, Date, trenched) %>%
filter(n > 1) %>%
select(tube.number, Date, trenched)
# Separate rows with true identical and ones with different values
# rows that share same moist/temp
identical_rows <- moisture_uruguay %>%
semi_join(dup_keys, by = c("tube.number", "Date", "trenched")) %>%
group_by(tube.number, Date, trenched, soil_moisture, T1_belowgr) %>%
filter(n() > 1) %>%
ungroup
# Rows where duplicates have different moisture/temp (conflicts)
conflicting_rows <- moisture_uruguay %>%
semi_join(dup_keys, by = c("tube.number", "Date", "trenched")) %>%
group_by(tube.number, Date, trenched) %>%
filter(n_distinct(soil_moisture) > 1 | n_distinct(T1_belowgr) > 1) %>%
ungroup()
# print to inspect
identical_rows %>%
arrange(tube.number, Date, trenched) %>%
print(n = Inf)
conflicting_rows %>%
arrange(tube.number, Date, trenched) %>%
print(n = Inf)
# Collapse duplicate rows
moisture_uruguay <- moisture_uruguay %>%
group_by(tube.number, Date, trenched) %>%
summarise(
soil_moisture = if_else(
n_distinct(soil_moisture) == 1, # identical moistures?
first(soil_moisture), # yes -> take any (first)
mean(soil_moisture, na.rm = TRUE) # no -> take mean
),
T1_belowgr = if_else(
n_distinct(T1_belowgr) == 1,
first(T1_belowgr),
mean(T1_belowgr, na.rm = TRUE)
),
.groups = "drop"
)
# Check duplicate rows again to confirm succesful collapsing
moisture_uruguay %>%
mutate(soil_moisture = round(soil_moisture, 4)) %>%
count(tube.number, Date, trenched) %>%  # how many duplicates with same point/date/trenched combo
filter(n > 1)
# JOINING
db_uruguay <- db_uruguay %>%
left_join(
moisture_uruguay,
by = c("point" = "tube.number", "date" = "Date", "trenched")
) %>%
mutate(
tsmoisture = if_else(is.na(tsmoisture) , soil_moisture * 100, tsmoisture),
t05 = if_else(is.na(t05), T1_belowgr, t05) # assumed that TOMST measures temperature at 5cm depth
) %>%
select(-soil_moisture, -T1_belowgr)
hist(db_uruguay$tsmoisture)
# ===========
# SAINT MITRE
# ===========
# separate db into saintmitre and others based on condition
condition_sm <- db$siteid == "Saint Mitre"
db_sm <- db %>% filter(condition_sm)
db_sm$point <- as.integer(db_sm$point)
# check
table_counts <- table(db_sm$point, db_sm$treatment)
rowSums(table_counts > 0) > 1
print(table_counts)
table_subsite <- table(db_sm$point, db_sm$subsiteid)
print(table_subsite)
colnames(table_subsite) <- c("ht_uv", "ht_nuv", "ht_t", "mt_uv", "mt_nuv", "mt_t", "nt_nuv", "nt_t")
print(table_subsite)
# ==================================
reticulate::repl_python()
library(dplyr)
library(ggplot2)
setwd("/scratch/project_2010938/Taavi_new")
df <- read.csv("holisoils_updated.csv", header = TRUE)
# Moisture distributions
par(mfrow = c(1,1))
for (site in unique(df$siteid)) {
df_subset <- df[df$siteid == site, ]
# Skip sites with no valid moisture data
if (all(is.na(df_subset$tsmoisture))) {
print(paste0("Skipping ", site))
next
}
hist(df_subset$tsmoisture,
main = paste0("Distribution of moisture in ", site),
xlab = "Moisture in SWC %",
ylab = "",
col = "lightgray",
border = "white")
# Add text box showing % of NAs for THIS site
legend("topright",
bty = "n",
legend = c(
paste0("% NAs: ", round(mean(is.na(df_subset$tsmoisture)) * 100, 1)),
paste0("0 values: ", sum(df_subset$tsmoisture == 0, na.rm = TRUE)),
paste0("n = ", length(df_subset$tsmoisture))
)
)
}
9757 + 212
reticulate::repl_python()
library(dplyr)
library(ggplot2)
setwd("/scratch/project_2010938/Taavi_new")
df <- read.csv("holisoils_updated.csv", header = TRUE)
# Moisture distributions
par(mfrow = c(1,1))
for (site in unique(df$siteid)) {
df_subset <- df[df$siteid == site, ]
# Skip sites with no valid moisture data
if (all(is.na(df_subset$tsmoisture))) {
print(paste0("Skipping ", site))
next
}
hist(df_subset$tsmoisture,
main = paste0("Distribution of moisture in ", site),
xlab = "Moisture in SWC %",
ylab = "",
col = "lightgray",
border = "white")
# Add text box showing % of NAs for THIS site
legend("topright",
bty = "n",
legend = c(
paste0("% NAs: ", round(mean(is.na(df_subset$tsmoisture)) * 100, 1)),
paste0("0 values: ", sum(df_subset$tsmoisture == 0, na.rm = TRUE)),
paste0("n = ", length(df_subset$tsmoisture))
)
)
}
df_uruguay <- df[df$siteid == "Rincondelbatovi", ]
ggplot(df_uruguay, aes(date, tsmoisture)) +
geom_line() +
labs(x = "date",
y = "moisture",
title = "timeseries of moisture in Uruguary") +
theme_minimal()
View(df_uruguay)
View(df)
df_uruguay <- df[df$siteid == "RincondelBatovi", ]
ggplot(df_uruguay, aes(date, tsmoisture)) +
geom_line() +
labs(x = "date",
y = "moisture",
title = "timeseries of moisture in Uruguary") +
theme_minimal()
library(dplyr)
library(ggplot2)
setwd("/scratch/project_2010938/Taavi_new")
df <- read.csv("holisoils_updated.csv", header = TRUE)
# Moisture distributions
par(mfrow = c(1,1))
for (site in unique(df$siteid)) {
df_subset <- df[df$siteid == site, ]
# Skip sites with no valid moisture data
if (all(is.na(df_subset$tsmoisture))) {
print(paste0("Skipping ", site))
next
}
hist(df_subset$tsmoisture,
main = paste0("Distribution of moisture in ", site),
xlab = "Moisture in SWC %",
ylab = "",
col = "lightgray",
border = "white")
# Add text box showing % of NAs for THIS site
legend("topright",
bty = "n",
legend = c(
paste0("% NAs: ", round(mean(is.na(df_subset$tsmoisture)) * 100, 1)),
paste0("0 values: ", sum(df_subset$tsmoisture == 0, na.rm = TRUE)),
paste0("n = ", length(df_subset$tsmoisture))
)
)
}
library(dplyr)
library(ggplot2)
setwd("/scratch/project_2010938/Taavi_new")
df <- read.csv("holisoils_updated.csv", header = TRUE)
View(df)
reticulate::repl_python()
load("/scratch/project_2010938/Taavi_new/moisturedata/lithuania/KCG_2023.RData")
load("/scratch/project_2010938/Taavi_new/moisturedata/lithuania/KCG_2024.RData")
# select wanted columns from Lithuanian data
KCG_2023 <- KCG_2023 %>%
select(Date, Label, "Obs#", ID, co2_flux, "IV T1", "IV H2O")
KCG_2024 <- KCG_2024 %>%
select(Date, Label, "Obs#", ID, co2_flux, "IV T1", "IV H2O")
# Combine into one dataframe
KCG <- rbind(KCG_2023, KCG_2024)
# rename to match db
names(KCG) <- c("date", "subsiteid", "point", "pointtype", "j_flux", "t05", "tsmoisture")
# add siteid
KCG$siteid <- "Kacergine"
# read in the database file
db <- read.csv("/scratch/project_2010938/Taavi_new/hs-combined-2025-09-29.csv", header = TRUE)
# change KGC$date to character
KCG <- KCG %>%
mutate(
date = as.character(date),
point = as.character(point)
)
# combine datasets
db_lt_added <- dplyr::bind_rows(db, KCG)
# save to new file (date 11.11.2025)
write.csv(db_lt_added, file = "/scratch/project_2010938/Taavi_new/hs-combined-2025-11-11.csv", rownames = FALSE)
load("/scratch/project_2010938/Taavi_new/moisturedata/lithuania/KCG_2023.RData")
load("/scratch/project_2010938/Taavi_new/moisturedata/lithuania/KCG_2024.RData")
# select wanted columns from Lithuanian data
KCG_2023 <- KCG_2023 %>%
select(Date, Label, "Obs#", ID, co2_flux, "IV T1", "IV H2O")
KCG_2024 <- KCG_2024 %>%
select(Date, Label, "Obs#", ID, co2_flux, "IV T1", "IV H2O")
# Combine into one dataframe
KCG <- rbind(KCG_2023, KCG_2024)
# rename to match db
names(KCG) <- c("date", "subsiteid", "point", "pointtype", "j_flux", "t05", "tsmoisture")
# add siteid
KCG$siteid <- "Kacergine"
# read in the database file
db <- read.csv("/scratch/project_2010938/Taavi_new/hs-combined-2025-09-29.csv", header = TRUE)
# change KGC$date to character
KCG <- KCG %>%
mutate(
date = as.character(date),
point = as.character(point)
)
# combine datasets
db_lt_added <- dplyr::bind_rows(db, KCG)
# save to new file (date 11.11.2025)
write.csv(db_lt_added, file = "/scratch/project_2010938/Taavi_new/hs-combined-2025-11-11.csv", rownames = FALSE)
# save to new file (date 11.11.2025)
write.csv(db_lt_added, file = "/scratch/project_2010938/Taavi_new/hs-combined-2025-11-11.csv", row.names = FALSE)
reticulate::repl_python()
